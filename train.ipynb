{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x131cc6e50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a corpus with 3 tokens: a, b and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Accepts a string or list of tokens.\n",
    "    Returns id2token and token2id dictionaries.\n",
    "\"\"\"\n",
    "def vocab_dicts(vocab):\n",
    "    vocab = sorted(set(vocab))\n",
    "    id2token = [\"<UNK>\", *vocab]\n",
    "    token2id = {token: i for i, token in enumerate(id2token)}\n",
    "    return id2token, token2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_vocab = \"abc\"\n",
    "\n",
    "# DEFINE Training Data\n",
    "small_data = [\n",
    "    \"aaa\",\n",
    "    \"bbb\",\n",
    "    \"ccc\"\n",
    "]\n",
    "\n",
    "id2token, token2id = vocab_dicts(small_vocab)\n",
    "           # i.e. {\"<UNK>\": 0, \"a\": 1, \"b\": 2, \"c\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More data\n",
    "def letter_sequences(num_examples, alphabet):\n",
    "    examples = []\n",
    "    for _ in range(num_examples):\n",
    "        length = random.randint(3, MAX_SEQ_LEN)\n",
    "        start = random.randint(0, len(alphabet) - length)\n",
    "        example = alphabet[start:start+length]\n",
    "        examples.append(example)\n",
    "    return pd.Series(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jklmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stuvw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuvwx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lmno</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence\n",
       "0    jklmn\n",
       "1     mnop\n",
       "2    stuvw\n",
       "3    tuvwx\n",
       "4     lmno"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "data = pd.DataFrame()\n",
    "data[\"sequence\"] = letter_sequences(10000, alphabet)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2token, token2id = vocab_dicts(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id for token 'a': 1\n",
      "token for id 1: a\n"
     ]
    }
   ],
   "source": [
    "print(\"id for token 'a':\", token2id['a'])\n",
    "print(\"token for id 1:\", id2token[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>actual</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jklmn</td>\n",
       "      <td>[10, 11, 12, 13, 14]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnop</td>\n",
       "      <td>[13, 14, 15, 16]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stuvw</td>\n",
       "      <td>[19, 20, 21, 22, 23]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuvwx</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[1, 1, 1, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lmno</td>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence                actual             mask\n",
       "0    jklmn  [10, 11, 12, 13, 14]  [1, 1, 1, 1, 1]\n",
       "1     mnop      [13, 14, 15, 16]     [1, 1, 1, 0]\n",
       "2    stuvw  [19, 20, 21, 22, 23]  [1, 1, 1, 1, 1]\n",
       "3    tuvwx  [20, 21, 22, 23, 24]  [1, 1, 1, 0, 1]\n",
       "4     lmno      [12, 13, 14, 15]     [1, 1, 1, 1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"actual\"] = data[\"sequence\"].apply(lambda x: [token2id[token] for token in x])\n",
    "data['mask'] = data['actual'].apply(lambda x: [1 if random.random() > 0.15 else 0 for _ in x])\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(row):\n",
    "    # mask is a list of 0s and 1s\n",
    "    return [a * m for a, m in zip(row['actual'], row['mask'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>actual</th>\n",
       "      <th>mask</th>\n",
       "      <th>ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jklmn</td>\n",
       "      <td>[10, 11, 12, 13, 14]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[10, 11, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnop</td>\n",
       "      <td>[13, 14, 15, 16]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[13, 14, 15, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stuvw</td>\n",
       "      <td>[19, 20, 21, 22, 23]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[19, 20, 21, 22, 23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuvwx</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[1, 1, 1, 0, 1]</td>\n",
       "      <td>[20, 21, 22, 0, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lmno</td>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence                actual             mask                    ex\n",
       "0    jklmn  [10, 11, 12, 13, 14]  [1, 1, 1, 1, 1]  [10, 11, 12, 13, 14]\n",
       "1     mnop      [13, 14, 15, 16]     [1, 1, 1, 0]       [13, 14, 15, 0]\n",
       "2    stuvw  [19, 20, 21, 22, 23]  [1, 1, 1, 1, 1]  [19, 20, 21, 22, 23]\n",
       "3    tuvwx  [20, 21, 22, 23, 24]  [1, 1, 1, 0, 1]   [20, 21, 22, 0, 24]\n",
       "4     lmno      [12, 13, 14, 15]     [1, 1, 1, 1]      [12, 13, 14, 15]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ex'] = data.apply(apply_mask, axis=1)\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>actual</th>\n",
       "      <th>mask</th>\n",
       "      <th>ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jklmn</td>\n",
       "      <td>[10, 11, 12, 13, 14]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[10, 11, 12, 13, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mnop</td>\n",
       "      <td>[13, 14, 15, 16]</td>\n",
       "      <td>[1, 1, 1, 0]</td>\n",
       "      <td>[13, 14, 15, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stuvw</td>\n",
       "      <td>[19, 20, 21, 22, 23]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[19, 20, 21, 22, 23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tuvwx</td>\n",
       "      <td>[20, 21, 22, 23, 24]</td>\n",
       "      <td>[1, 1, 1, 0, 1]</td>\n",
       "      <td>[20, 21, 22, 0, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lmno</td>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "      <td>[1, 1, 1, 1]</td>\n",
       "      <td>[12, 13, 14, 15]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence                actual             mask                    ex\n",
       "0    jklmn  [10, 11, 12, 13, 14]  [1, 1, 1, 1, 1]  [10, 11, 12, 13, 14]\n",
       "1     mnop      [13, 14, 15, 16]     [1, 1, 1, 0]       [13, 14, 15, 0]\n",
       "2    stuvw  [19, 20, 21, 22, 23]  [1, 1, 1, 1, 1]  [19, 20, 21, 22, 23]\n",
       "3    tuvwx  [20, 21, 22, 23, 24]  [1, 1, 1, 0, 1]   [20, 21, 22, 0, 24]\n",
       "4     lmno      [12, 13, 14, 15]     [1, 1, 1, 1]      [12, 13, 14, 15]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.actual = data['actual']\n",
    "        self.ex = data['ex']\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.actual)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.actual.iloc[idx], self.ex.iloc[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(batch, max_len=MAX_SEQ_LEN):\n",
    "\n",
    "    batch_size = len(batch)\n",
    "    max_len = MAX_SEQ_LEN\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    actual_padded = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "    ex_padded = torch.zeros(batch_size, max_len, dtype=torch.long)\n",
    "    padding_masks = torch.zeros(batch_size, max_len, dtype=torch.bool)\n",
    "\n",
    "    for i, (seq_actual, seq_ex) in enumerate(batch):\n",
    "        length = len(seq_actual)\n",
    "\n",
    "        seq_actual = torch.tensor(seq_actual)\n",
    "        seq_ex = torch.tensor(seq_ex)\n",
    "\n",
    "        actual_padded[i, :len(seq_actual)] = seq_actual\n",
    "        ex_padded[i, :len(seq_ex)] = seq_ex\n",
    "        padding_masks[i, :length] = True\n",
    "\n",
    "    return actual_padded, ex_padded, padding_masks\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True],\n",
      "        [ True,  True,  True, False, False, False, False],\n",
      "        [ True,  True,  True,  True, False, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True, False],\n",
      "        [ True,  True,  True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "# get next item\n",
    "a, x, p = next(iter(dataloader))\n",
    "print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Attention(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(EMB_DIM, EMB_DIM)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.emb(x)\n",
    "#         # Linear layer?\n",
    "#         atn = x @ x.T\n",
    "#         atn = F.softmax(atn, -1)\n",
    "#         enc = atn @ x\n",
    "#         return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "VOCAB_SIZE = len(token2id) # 27\n",
    "EMB_DIM = 8\n",
    "MAX_SEQ_LEN = 7\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, emb_dim=EMB_DIM):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim)\n",
    "        # LINEAR LAYER to use inside attention mechanism!?!?!\n",
    "        self.out = nn.Linear(emb_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, padding_mask=None):\n",
    "\n",
    "        x = self.emb(x)\n",
    "\n",
    "        # Here we'd do positional encoding :P\n",
    "        scores = x @ x.transpose(-2, -1)\n",
    "        # print(\"\\nAttention scores before mask:\", \n",
    "        #       \"\\nmin:\", scores.min().item(),\n",
    "        #       \"\\nmax:\", scores.max().item())\n",
    "\n",
    "        if padding_mask is not None:\n",
    "            attention_mask = padding_mask.unsqueeze(1) & padding_mask.unsqueeze(2)\n",
    "            # print(\"\\nAttention mask sample:\")\n",
    "            # print(attention_mask[0, :3, :3])  # Show first 3x3 of first batch\n",
    "            \n",
    "            scores = scores.masked_fill(~attention_mask, -1e9)\n",
    "            scores = scores / math.sqrt(x.size(-1))\n",
    "            # print(\"\\nAttention scores after mask:\", \n",
    "            #       \"\\nmin:\", scores.min().item(),\n",
    "            #       \"\\nmax:\", scores.max().item())\n",
    "        \n",
    "        \n",
    "        atn = F.softmax(scores, -1)\n",
    "        # print(\"\\nAttention weights after softmax:\",\n",
    "        #       \"\\nmin:\", atn.min().item(),\n",
    "        #       \"\\nmax:\", atn.max().item())\n",
    "        \n",
    "        enc = atn @ x\n",
    "        logits = self.out(enc)\n",
    "        # print(\"\\nLogits:\",\n",
    "        #       \"\\nmin:\", logits.min().item(),\n",
    "        #       \"\\nmax:\", logits.max().item(),\n",
    "        #       \"\\nShape:\", logits.shape)\n",
    "        \n",
    "        # probs = F.softmax(logits, dim=-1)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTransformer()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/x25bd/Code/mlx/week-4/mlx5.4-transformers/wandb/run-20241106_180611-8d8jbxmj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/machine-learning-institute/mlx5.4-transformers/runs/8d8jbxmj' target=\"_blank\">simple-transformer-alphabet</a></strong> to <a href='https://wandb.ai/machine-learning-institute/mlx5.4-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/machine-learning-institute/mlx5.4-transformers' target=\"_blank\">https://wandb.ai/machine-learning-institute/mlx5.4-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/machine-learning-institute/mlx5.4-transformers/runs/8d8jbxmj' target=\"_blank\">https://wandb.ai/machine-learning-institute/mlx5.4-transformers/runs/8d8jbxmj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1500 [00:00<14:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0, Batch 624\n",
      "Predicted: <UNK><UNK><UNK><UNK>t<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1500 [00:05<11:35,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10, Batch 624\n",
      "Predicted: <UNK>qrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 21/1500 [00:09<10:24,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20, Batch 624\n",
      "Predicted: sqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 31/1500 [00:14<10:51,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 41/1500 [00:18<10:58,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 51/1500 [00:23<10:41,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 61/1500 [00:27<10:12,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 71/1500 [00:32<10:09,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 81/1500 [00:36<09:18,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 91/1500 [00:41<11:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 101/1500 [00:45<10:02,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 111/1500 [00:50<10:16,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 110, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 121/1500 [00:55<12:40,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 120, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 131/1500 [01:00<11:01,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 130, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 141/1500 [01:05<11:35,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 140, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 151/1500 [01:10<10:02,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 150, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 161/1500 [01:15<09:56,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 160, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 171/1500 [01:20<10:48,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 170, Batch 624\n",
      "Predicted: qqrst<UNK><UNK>\n",
      "Actual:    pqrst<UNK><UNK>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 172/1500 [01:20<10:24,  2.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Debug prints\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1500\u001b[39m)):\n\u001b[0;32m----> 9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVOCAB_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/mlx/week-4/mlx5.4-transformers/venv-transformers/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/Code/mlx/week-4/mlx5.4-transformers/venv-transformers/lib/python3.12/site-packages/torch/utils/data/dataloader.py:756\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/Code/mlx/week-4/mlx5.4-transformers/venv-transformers/lib/python3.12/site-packages/torch/utils/data/dataloader.py:691\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/mlx/week-4/mlx5.4-transformers/venv-transformers/lib/python3.12/site-packages/torch/utils/data/sampler.py:350\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m batch[idx_in_batch] \u001b[38;5;241m=\u001b[39m idx\n\u001b[1;32m    349\u001b[0m idx_in_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx_in_batch \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m batch\n\u001b[1;32m    352\u001b[0m     idx_in_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Trainin loop\n",
    "# Add wandb logging\n",
    "import wandb\n",
    "wandb.init(project=\"mlx5.4-transformers\", name=\"simple-transformer-alphabet\")\n",
    "model.train()\n",
    "# Debug prints\n",
    "\n",
    "for epoch in tqdm(range(1500)):\n",
    "    for i, (actual, ex, mask) in enumerate(dataloader):\n",
    "        logits = model(ex, mask) \n",
    "        logits = logits.view(-1, VOCAB_SIZE)\n",
    "        actual = actual.view(-1)\n",
    "\n",
    "        loss = F.cross_entropy(logits, actual)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        wandb.log({\"loss\": loss})\n",
    "    # Validate every N batches\n",
    "    if epoch % 10 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Get predictions for first sequence in batch\n",
    "            pred = torch.argmax(logits.view(ex.shape[0], -1, VOCAB_SIZE)[0], dim=-1)\n",
    "            act = actual.view(ex.shape[0], -1)[0]\n",
    "            \n",
    "            pred_tokens = ''.join([id2token[i.item()] for i in pred])\n",
    "            actual_tokens = ''.join([id2token[i.item()] for i in act])\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch}, Batch {i}\")\n",
    "            print(f\"Predicted: {pred_tokens}\")\n",
    "            print(f\"Actual:    {actual_tokens}\")\n",
    "        model.train()\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, x, m = next(iter(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 1:\n",
      "Predicted: jklmn<UNK><UNK>\n",
      "Actual:    jklmn<UNK><UNK>\n",
      "\n",
      "Example 2:\n",
      "Predicted: mno<UNK><UNK><UNK><UNK>\n",
      "Actual:    mnop<UNK><UNK><UNK>\n",
      "\n",
      "Example 3:\n",
      "Predicted: stuvw<UNK><UNK>\n",
      "Actual:    stuvw<UNK><UNK>\n",
      "\n",
      "Example 4:\n",
      "Predicted: tuvxx<UNK><UNK>\n",
      "Actual:    tuvwx<UNK><UNK>\n",
      "\n",
      "Example 5:\n",
      "Predicted: lmno<UNK><UNK><UNK>\n",
      "Actual:    lmno<UNK><UNK><UNK>\n",
      "\n",
      "Example 6:\n",
      "Predicted: ijklmnl\n",
      "Actual:    ijklmno\n",
      "\n",
      "Example 7:\n",
      "Predicted: ijklm<UNK><UNK>\n",
      "Actual:    ijklm<UNK><UNK>\n",
      "\n",
      "Example 8:\n",
      "Predicted: vwxyx<UNK><UNK>\n",
      "Actual:    vwxyz<UNK><UNK>\n",
      "\n",
      "Example 9:\n",
      "Predicted: <UNK><UNK>pq<UNK><UNK><UNK>\n",
      "Actual:    nopq<UNK><UNK><UNK>\n",
      "\n",
      "Example 10:\n",
      "Predicted: uvxxy<UNK><UNK>\n",
      "Actual:    uvwxy<UNK><UNK>\n",
      "\n",
      "Example 11:\n",
      "Predicted: abcdefg\n",
      "Actual:    abcdefg\n",
      "\n",
      "Example 12:\n",
      "Predicted: ij<UNK><UNK><UNK><UNK><UNK>\n",
      "Actual:    ijk<UNK><UNK><UNK><UNK>\n",
      "\n",
      "Example 13:\n",
      "Predicted: w<UNK>y<UNK><UNK><UNK><UNK>\n",
      "Actual:    wxyz<UNK><UNK><UNK>\n",
      "\n",
      "Example 14:\n",
      "Predicted: abcdef<UNK>\n",
      "Actual:    abcdef<UNK>\n",
      "\n",
      "Example 15:\n",
      "Predicted: fggij<UNK><UNK>\n",
      "Actual:    fghij<UNK><UNK>\n"
     ]
    }
   ],
   "source": [
    "def validate_predictions(model, dataloader, id2token, n_examples=15):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get one batch\n",
    "        actual, example, mask = next(iter(dataloader))\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = model(example, mask)  # [batch, seq, vocab]\n",
    "        \n",
    "        # For each example in batch (up to n_examples)\n",
    "        for i in range(min(n_examples, len(actual))):\n",
    "            # Get single sequence\n",
    "            seq_probs = logits[i]  # # apply softmax???\n",
    "            seq_actual = actual[i]  # [seq]\n",
    "            \n",
    "            # Get predicted tokens\n",
    "            predicted_indices = torch.argmax(seq_probs, dim=-1)  # [seq]\n",
    "            \n",
    "            # Convert to letters\n",
    "            pred_tokens = [id2token[idx.item()] for idx in predicted_indices]\n",
    "            actual_tokens = [id2token[idx.item()] for idx in seq_actual]\n",
    "            \n",
    "            print(f\"\\nExample {i+1}:\")\n",
    "            print(f\"Predicted: {''.join(pred_tokens)}\")\n",
    "            print(f\"Actual:    {''.join(actual_tokens)}\")\n",
    "\n",
    "# Run validation\n",
    "validate_predictions(model, dataloader, id2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, x, m = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
